{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Notebook for comparing our generative models\n",
    "\n",
    "Contains\n",
    "\n",
    "- Frechet LeNet5 distance\n",
    "- Label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes, matplotlib.figure\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from lenet import LeNet5\n",
    "import distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_file_save = False # Set to True to save figures etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "if cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using device\", device)\n",
    "\n",
    "# Disable GPU always\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test = np.load('data/mnist_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leNet_classifier = LeNet5(n_classes=10).to(device)\n",
    "leNet_classifier.load_state_dict(torch.load('models/mnist_lenet5.pth'))\n",
    "leNet_classifier.eval();\n",
    "\n",
    "def _np_to_net(images):\n",
    "    images = torch.from_numpy(images).to(device).float()\n",
    "    images = torch.unsqueeze(images, dim=1) # add channel dimension\n",
    "    resize = transforms.Resize((32, 32)) # LeNet expects 32x32 size images\n",
    "    images = resize.forward(images)\n",
    "    return images\n",
    "\n",
    "def _net_to_np(array):\n",
    "    return array.cpu().detach().numpy()\n",
    "\n",
    "def classify_images(images):\n",
    "    images = _np_to_net(images)\n",
    "    _, probs = leNet_classifier.forward(images)\n",
    "    probs = _net_to_np(probs)\n",
    "    predicted_class = np.argmax(probs, axis=1)\n",
    "    return predicted_class\n",
    "\n",
    "def embed_images(images):\n",
    "    images = _np_to_net(images)\n",
    "    embedding = leNet_classifier.forward_headless(images)\n",
    "    embedding = _net_to_np(embedding)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification(images, dataset_name):\n",
    "    \n",
    "    classes = classify_images(images)\n",
    "    fig, axs = plt.subplots(1, len(images), figsize=(12, 1.6))\n",
    "    fig.suptitle(\"Image classification with LeNet5 for %s\" % dataset_name)\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        ax = axs[i]\n",
    "        img = images[i]\n",
    "        img = np.clip(img, 0, 1)\n",
    "        ax.imshow(img, cmap='gray_r')\n",
    "        ax.set_title(\"%s\" % classes[i]),\n",
    "        ax.set_xticks([]), ax.set_yticks([])\n",
    "    \n",
    "    if enable_file_save:\n",
    "        plt.savefig('plots/LeNet_classification_examples_%s.png' % dataset_name.replace(' ', '_'))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_classification(mnist_test[:15], 'MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gaussian(data):\n",
    "    mean = np.mean(data, axis=0)\n",
    "    cov = np.cov(data, rowvar=0)\n",
    "    assert mean.shape == data.shape[1:]\n",
    "    assert cov.shape == (len(mean), len(mean))\n",
    "    \n",
    "    return mean, cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, work with two datasets which are disjoint subsets of MNIST\n",
    "samples1 = mnist_test[:20]\n",
    "samples2 = mnist_test[20:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified1 = embed_images(samples1)\n",
    "classified2 = embed_images(samples2)\n",
    "gauss1 = fit_gaussian(classified1)\n",
    "gauss2 = fit_gaussian(classified2)\n",
    "frechet_dist = distances.frechet_distance(gauss1, gauss2)\n",
    "\n",
    "# small numerical error can give complex distance\n",
    "assert np.abs(np.imag(frechet_dist)) < 1e-6, np.max(np.abs(np.imag(frechet_dist)))\n",
    "frechet_dist = np.real(frechet_dist)\n",
    "\n",
    "print(frechet_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_files = [\n",
    "    'data/mnist_test.npy',\n",
    "    'data/FC_VAE_samples.npy',\n",
    "    'data/convolutional_VAE_samples.npy',\n",
    "    'data/diffusion_samples.npy',\n",
    "]\n",
    "\n",
    "dataset_titles = [\n",
    "    'MNIST test set',\n",
    "    'Simple Variational Autoencoder',\n",
    "    'Convolutional Variational Autoencoder',\n",
    "    'Diffusion model',\n",
    "]\n",
    "\n",
    "for file in datasets_files:\n",
    "    assert os.path.exists(file), file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference, the MNIST training set\n",
    "mnist_train = np.load('data/mnist_train.npy')\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Fr%C3%A9chet_inception_distance\n",
    "reference_gaussian = fit_gaussian(embed_images(mnist_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load generated images\n",
    "datasets = [np.load(file) for file in datasets_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FLD scores\")\n",
    "print(\"==========\")\n",
    "scores = dict()\n",
    "for d in range(len(dataset_titles)):\n",
    "    images = datasets[d]\n",
    "    name = dataset_titles[d]\n",
    "    model_gaussian = fit_gaussian(embed_images(images))\n",
    "    frechet_dist = distances.frechet_distance(reference_gaussian, model_gaussian)\n",
    "    print('{0:40}  {1}'.format(name, frechet_dist))\n",
    "    scores[name] = frechet_dist\n",
    "\n",
    "print(\"==========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write scores to CSV file\n",
    "if enable_file_save:\n",
    "    with open('data/fld_scores.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(('Model', 'Score'))\n",
    "        for row in scores.items():\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_datasets = [mnist_train] + datasets[1:]\n",
    "histogram_series_labels = ['MNIST training set'] + dataset_titles[1:] \n",
    "class_distributions = [classify_images(images) for images in histogram_datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of distribution of class predictions\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "\n",
    "# workaround to get x-axis labels correct\n",
    "# https://stackoverflow.com/a/27084005\n",
    "bins=np.arange(11)-0.5\n",
    "\n",
    "plt.hist(class_distributions, bins, density=True, histtype='bar', label=histogram_series_labels)\n",
    "fontsize = 12\n",
    "plt.xlabel('Image label', fontsize=fontsize)\n",
    "plt.ylabel('Frequency', fontsize=fontsize)\n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "plt.xticks(range(10), fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.legend(fontsize=fontsize)\n",
    "\n",
    "if enable_file_save:\n",
    "    fig.dpi = 500\n",
    "    plt.savefig('plots/class_distribution_histogram.png')\n",
    "\n",
    "#plt.title('Distribution of generated images (and MNIST training set)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot classification of some of our generated images\n",
    "for d in range(len(datasets)):\n",
    "    images = datasets[d]\n",
    "    name = dataset_titles[d]\n",
    "    plot_classification(images[:15], name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d8d7019ea07486b9b3f42d10adfdabc3c0ed99a04a0337cb961ee7609e50b1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
