{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a37bfd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c65af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b942582",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5a136d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, encoded_space_dim):\n",
    "        super().__init__()\n",
    "        self.d = encoded_space_dim\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3 * 3 * 32, 128),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.encoderMu = nn.Linear(128, self.d)\n",
    "        self.encoderlogvar = nn.Linear(128, self.d)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.d, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 3 * 3 * 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Unflatten(dim=1, unflattened_size=(32, 3, 3)),\n",
    "            nn.ConvTranspose2d(32, 16, 3, \n",
    "            stride=2, output_padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 3, stride=2, \n",
    "            padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 3, stride=2, \n",
    "            padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "       )\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_enc = self.encoder1(x)\n",
    "        mu = self.encoderMu(x_enc)\n",
    "        logvar = self.encoderlogvar(x_enc)\n",
    "        z = self.reparameterize(mu,logvar)\n",
    "        out = self.decoder(z)\n",
    "        return out, mu, logvar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "207267d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "model = NeuralNetwork(latent_dim).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5404234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(x, mu_x, mu_z, logvar_z):\n",
    "    lnP = torch.nn.functional.mse_loss(x, mu_x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar_z - mu_z.pow(2) - logvar_z.exp())\n",
    "    return lnP + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be7ae6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = loss_function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3,weight_decay=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99ee6cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch, (X, _) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred, mu, logvar = model(X)\n",
    "        loss = loss_fn(X,  pred, mu, logvar)\n",
    "        epoch_loss += loss.detach().cpu().item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    return epoch_loss / size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae377926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, _ in dataloader:\n",
    "            X = X.to(device)\n",
    "            pred, mu, logvar = model(X)\n",
    "            test_loss += loss_fn(X, pred, mu, logvar).detach().item()\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b16143f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 37812.117188  [    0/60000]\n",
      "loss: 17340.109375  [25600/60000]\n",
      "loss: 14717.802734  [51200/60000]\n",
      "Avg loss: 13456.985857 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 13451.765625  [    0/60000]\n",
      "loss: 12210.005859  [25600/60000]\n",
      "loss: 12993.586914  [51200/60000]\n",
      "Avg loss: 12090.999168 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 11979.604492  [    0/60000]\n",
      "loss: 11518.041016  [25600/60000]\n",
      "loss: 12504.638672  [51200/60000]\n",
      "Avg loss: 11680.448878 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 11578.899414  [    0/60000]\n",
      "loss: 11185.214844  [25600/60000]\n",
      "loss: 12098.350586  [51200/60000]\n",
      "Avg loss: 11335.273596 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 11159.579102  [    0/60000]\n",
      "loss: 10891.827148  [25600/60000]\n",
      "loss: 11671.760742  [51200/60000]\n",
      "Avg loss: 11097.981107 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 10882.238281  [    0/60000]\n",
      "loss: 10596.867188  [25600/60000]\n",
      "loss: 11371.531250  [51200/60000]\n",
      "Avg loss: 10767.147006 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 10481.627930  [    0/60000]\n",
      "loss: 10333.162109  [25600/60000]\n",
      "loss: 11004.920898  [51200/60000]\n",
      "Avg loss: 10556.201840 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 10287.728516  [    0/60000]\n",
      "loss: 10156.873047  [25600/60000]\n",
      "loss: 10735.387695  [51200/60000]\n",
      "Avg loss: 10328.997525 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 10032.989258  [    0/60000]\n",
      "loss: 9994.148438  [25600/60000]\n",
      "loss: 10567.726562  [51200/60000]\n",
      "Avg loss: 10135.656479 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 9816.305664  [    0/60000]\n",
      "loss: 9828.324219  [25600/60000]\n",
      "loss: 10166.592773  [51200/60000]\n",
      "Avg loss: 9826.871925 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 9501.987305  [    0/60000]\n",
      "loss: 9537.223633  [25600/60000]\n",
      "loss: 9901.916016  [51200/60000]\n",
      "Avg loss: 9684.293373 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 9287.084961  [    0/60000]\n",
      "loss: 9404.958984  [25600/60000]\n",
      "loss: 9785.095703  [51200/60000]\n",
      "Avg loss: 9569.455209 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 9135.257812  [    0/60000]\n",
      "loss: 9280.038086  [25600/60000]\n",
      "loss: 9755.114258  [51200/60000]\n",
      "Avg loss: 9563.119034 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 9171.080078  [    0/60000]\n",
      "loss: 9219.525391  [25600/60000]\n",
      "loss: 9667.231445  [51200/60000]\n",
      "Avg loss: 9419.022043 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 9016.435547  [    0/60000]\n",
      "loss: 9163.593750  [25600/60000]\n",
      "loss: 9671.010742  [51200/60000]\n",
      "Avg loss: 9449.184900 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 8972.879883  [    0/60000]\n",
      "loss: 9110.107422  [25600/60000]\n",
      "loss: 9564.135742  [51200/60000]\n",
      "Avg loss: 9366.937152 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 8912.852539  [    0/60000]\n",
      "loss: 9043.069336  [25600/60000]\n",
      "loss: 9512.773438  [51200/60000]\n",
      "Avg loss: 9344.672249 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 8896.537109  [    0/60000]\n",
      "loss: 8999.099609  [25600/60000]\n",
      "loss: 9493.987305  [51200/60000]\n",
      "Avg loss: 9318.774463 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 8813.525391  [    0/60000]\n",
      "loss: 9043.286133  [25600/60000]\n",
      "loss: 9465.838867  [51200/60000]\n",
      "Avg loss: 9305.002289 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 8862.131836  [    0/60000]\n",
      "loss: 8970.978516  [25600/60000]\n",
      "loss: 9417.737305  [51200/60000]\n",
      "Avg loss: 9291.790698 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 8834.156250  [    0/60000]\n",
      "loss: 8967.932617  [25600/60000]\n",
      "loss: 9421.795898  [51200/60000]\n",
      "Avg loss: 9219.659174 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 8685.041016  [    0/60000]\n",
      "loss: 8964.376953  [25600/60000]\n",
      "loss: 9279.807617  [51200/60000]\n",
      "Avg loss: 9181.720303 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 8700.922852  [    0/60000]\n",
      "loss: 8868.510742  [25600/60000]\n",
      "loss: 9369.488281  [51200/60000]\n",
      "Avg loss: 9224.417377 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 8722.630859  [    0/60000]\n",
      "loss: 8923.162109  [25600/60000]\n",
      "loss: 9307.591797  [51200/60000]\n",
      "Avg loss: 9207.638568 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 8673.755859  [    0/60000]\n",
      "loss: 8854.244141  [25600/60000]\n",
      "loss: 9298.384766  [51200/60000]\n",
      "Avg loss: 9147.589211 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 8603.130859  [    0/60000]\n",
      "loss: 8886.701172  [25600/60000]\n",
      "loss: 9332.015625  [51200/60000]\n",
      "Avg loss: 9124.820248 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 8563.537109  [    0/60000]\n",
      "loss: 8823.639648  [25600/60000]\n",
      "loss: 9268.716797  [51200/60000]\n",
      "Avg loss: 9139.639903 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 8664.266602  [    0/60000]\n",
      "loss: 8810.771484  [25600/60000]\n",
      "loss: 9327.427734  [51200/60000]\n",
      "Avg loss: 9124.086128 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 8572.912109  [    0/60000]\n",
      "loss: 8874.393555  [25600/60000]\n",
      "loss: 9196.162109  [51200/60000]\n",
      "Avg loss: 9101.329279 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 8644.776367  [    0/60000]\n",
      "loss: 8799.646484  [25600/60000]\n",
      "loss: 9317.469727  [51200/60000]\n",
      "Avg loss: 9086.898621 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 8600.641602  [    0/60000]\n",
      "loss: 8758.044922  [25600/60000]\n",
      "loss: 9177.275391  [51200/60000]\n",
      "Avg loss: 9050.172607 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 8581.776367  [    0/60000]\n",
      "loss: 8786.023438  [25600/60000]\n",
      "loss: 9230.423828  [51200/60000]\n",
      "Avg loss: 9074.435541 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 8586.215820  [    0/60000]\n",
      "loss: 8769.113281  [25600/60000]\n",
      "loss: 9238.669922  [51200/60000]\n",
      "Avg loss: 9060.825800 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 8536.102539  [    0/60000]\n",
      "loss: 8817.001953  [25600/60000]\n",
      "loss: 9197.078125  [51200/60000]\n",
      "Avg loss: 9052.264502 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 8518.671875  [    0/60000]\n",
      "loss: 8820.750977  [25600/60000]\n",
      "loss: 9149.966797  [51200/60000]\n",
      "Avg loss: 9022.653365 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 8462.093750  [    0/60000]\n",
      "loss: 8811.173828  [25600/60000]\n",
      "loss: 9184.397461  [51200/60000]\n",
      "Avg loss: 9033.686832 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 8539.333984  [    0/60000]\n",
      "loss: 8794.837891  [25600/60000]\n",
      "loss: 9099.698242  [51200/60000]\n",
      "Avg loss: 9027.577078 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 8460.740234  [    0/60000]\n",
      "loss: 8746.346680  [25600/60000]\n",
      "loss: 9057.336914  [51200/60000]\n",
      "Avg loss: 9017.914172 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 8619.111328  [    0/60000]\n",
      "loss: 8711.695312  [25600/60000]\n",
      "loss: 9106.258789  [51200/60000]\n",
      "Avg loss: 9017.651044 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 8528.347656  [    0/60000]\n",
      "loss: 8752.222656  [25600/60000]\n",
      "loss: 9056.611328  [51200/60000]\n",
      "Avg loss: 9008.850084 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 8489.385742  [    0/60000]\n",
      "loss: 8742.494141  [25600/60000]\n",
      "loss: 9172.435547  [51200/60000]\n",
      "Avg loss: 8999.519756 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 8514.343750  [    0/60000]\n",
      "loss: 8753.537109  [25600/60000]\n",
      "loss: 9069.662109  [51200/60000]\n",
      "Avg loss: 9012.630182 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 8507.315430  [    0/60000]\n",
      "loss: 8716.217773  [25600/60000]\n",
      "loss: 9059.591797  [51200/60000]\n",
      "Avg loss: 9002.366507 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 8501.043945  [    0/60000]\n",
      "loss: 8754.867188  [25600/60000]\n",
      "loss: 9082.339844  [51200/60000]\n",
      "Avg loss: 9001.209169 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 8580.613281  [    0/60000]\n",
      "loss: 8709.907227  [25600/60000]\n",
      "loss: 9070.286133  [51200/60000]\n",
      "Avg loss: 8969.130876 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 8492.115234  [    0/60000]\n",
      "loss: 8690.424805  [25600/60000]\n",
      "loss: 9022.709961  [51200/60000]\n",
      "Avg loss: 8959.558833 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 8437.739258  [    0/60000]\n",
      "loss: 8719.555664  [25600/60000]\n",
      "loss: 9030.304688  [51200/60000]\n",
      "Avg loss: 8988.482309 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 8545.262695  [    0/60000]\n",
      "loss: 8689.148438  [25600/60000]\n",
      "loss: 9049.603516  [51200/60000]\n",
      "Avg loss: 8976.213748 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 8576.082031  [    0/60000]\n",
      "loss: 8668.949219  [25600/60000]\n",
      "loss: 8964.787109  [51200/60000]\n",
      "Avg loss: 8997.391774 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 8569.777344  [    0/60000]\n",
      "loss: 8711.069336  [25600/60000]\n",
      "loss: 8968.305664  [51200/60000]\n",
      "Avg loss: 8961.956203 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 8518.228516  [    0/60000]\n",
      "loss: 8690.825195  [25600/60000]\n",
      "loss: 9109.853516  [51200/60000]\n",
      "Avg loss: 8951.887927 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 8552.377930  [    0/60000]\n",
      "loss: 8702.258789  [25600/60000]\n",
      "loss: 8967.777344  [51200/60000]\n",
      "Avg loss: 8943.095427 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 8472.495117  [    0/60000]\n",
      "loss: 8638.247070  [25600/60000]\n",
      "loss: 8981.435547  [51200/60000]\n",
      "Avg loss: 8941.034297 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 8524.085938  [    0/60000]\n",
      "loss: 8736.541016  [25600/60000]\n",
      "loss: 8933.022461  [51200/60000]\n",
      "Avg loss: 8952.522826 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 8565.901367  [    0/60000]\n",
      "loss: 8686.977539  [25600/60000]\n",
      "loss: 8920.296875  [51200/60000]\n",
      "Avg loss: 8927.063632 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 8432.400391  [    0/60000]\n",
      "loss: 8647.064453  [25600/60000]\n",
      "loss: 8987.882812  [51200/60000]\n",
      "Avg loss: 8924.683307 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 8565.450195  [    0/60000]\n",
      "loss: 8675.245117  [25600/60000]\n",
      "loss: 8932.224609  [51200/60000]\n",
      "Avg loss: 8920.176932 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 8388.212891  [    0/60000]\n",
      "loss: 8609.632812  [25600/60000]\n",
      "loss: 8989.423828  [51200/60000]\n",
      "Avg loss: 8890.453613 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 8458.431641  [    0/60000]\n",
      "loss: 8691.414062  [25600/60000]\n",
      "loss: 8896.951172  [51200/60000]\n",
      "Avg loss: 8920.735136 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 8432.248047  [    0/60000]\n",
      "loss: 8664.839844  [25600/60000]\n",
      "loss: 8980.521484  [51200/60000]\n",
      "Avg loss: 8936.487738 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 8533.471680  [    0/60000]\n",
      "loss: 8609.753906  [25600/60000]\n",
      "loss: 8934.925781  [51200/60000]\n",
      "Avg loss: 8889.653690 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 8375.971680  [    0/60000]\n",
      "loss: 8642.343750  [25600/60000]\n",
      "loss: 8809.839844  [51200/60000]\n",
      "Avg loss: 8924.252724 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 8495.548828  [    0/60000]\n",
      "loss: 8628.747070  [25600/60000]\n",
      "loss: 8889.204102  [51200/60000]\n",
      "Avg loss: 8929.600027 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 8544.269531  [    0/60000]\n",
      "loss: 8624.037109  [25600/60000]\n",
      "loss: 8903.975586  [51200/60000]\n",
      "Avg loss: 8893.691324 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 8481.212891  [    0/60000]\n",
      "loss: 8698.829102  [25600/60000]\n",
      "loss: 8915.050781  [51200/60000]\n",
      "Avg loss: 8887.692499 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 8426.642578  [    0/60000]\n",
      "loss: 8639.884766  [25600/60000]\n",
      "loss: 8879.513672  [51200/60000]\n",
      "Avg loss: 8878.480748 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 8408.237305  [    0/60000]\n",
      "loss: 8627.088867  [25600/60000]\n",
      "loss: 8902.345703  [51200/60000]\n",
      "Avg loss: 8862.055881 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 8488.558594  [    0/60000]\n",
      "loss: 8632.824219  [25600/60000]\n",
      "loss: 8874.804688  [51200/60000]\n",
      "Avg loss: 8911.298157 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 8480.909180  [    0/60000]\n",
      "loss: 8612.340820  [25600/60000]\n",
      "loss: 8859.830078  [51200/60000]\n",
      "Avg loss: 8864.697203 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 8476.050781  [    0/60000]\n",
      "loss: 8589.931641  [25600/60000]\n",
      "loss: 8869.221680  [51200/60000]\n",
      "Avg loss: 8859.929353 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 8380.119141  [    0/60000]\n",
      "loss: 8600.666016  [25600/60000]\n",
      "loss: 8810.033203  [51200/60000]\n",
      "Avg loss: 8879.925639 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 8464.895508  [    0/60000]\n",
      "loss: 8627.460938  [25600/60000]\n",
      "loss: 8841.880859  [51200/60000]\n",
      "Avg loss: 8863.634056 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 8399.509766  [    0/60000]\n",
      "loss: 8582.894531  [25600/60000]\n",
      "loss: 8766.606445  [51200/60000]\n",
      "Avg loss: 8859.320946 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 8353.708984  [    0/60000]\n",
      "loss: 8524.893555  [25600/60000]\n",
      "loss: 8839.226562  [51200/60000]\n",
      "Avg loss: 8863.765620 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 8441.865234  [    0/60000]\n",
      "loss: 8662.295898  [25600/60000]\n",
      "loss: 8821.979492  [51200/60000]\n",
      "Avg loss: 8879.593486 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 8404.527344  [    0/60000]\n",
      "loss: 8658.140625  [25600/60000]\n",
      "loss: 8821.844727  [51200/60000]\n",
      "Avg loss: 8857.274680 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 8342.176758  [    0/60000]\n",
      "loss: 8592.113281  [25600/60000]\n",
      "loss: 8822.361328  [51200/60000]\n",
      "Avg loss: 8861.461038 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 8381.157227  [    0/60000]\n",
      "loss: 8586.159180  [25600/60000]\n",
      "loss: 8814.466797  [51200/60000]\n",
      "Avg loss: 8830.846643 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 8396.794922  [    0/60000]\n",
      "loss: 8569.876953  [25600/60000]\n",
      "loss: 8827.177734  [51200/60000]\n",
      "Avg loss: 8819.311539 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 8397.628906  [    0/60000]\n",
      "loss: 8665.157227  [25600/60000]\n",
      "loss: 8737.018555  [51200/60000]\n",
      "Avg loss: 8817.715932 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 8376.316406  [    0/60000]\n",
      "loss: 8607.969727  [25600/60000]\n",
      "loss: 8775.792969  [51200/60000]\n",
      "Avg loss: 8814.531651 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 8328.049805  [    0/60000]\n",
      "loss: 8609.428711  [25600/60000]\n",
      "loss: 8785.890625  [51200/60000]\n",
      "Avg loss: 8826.104375 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 8293.708984  [    0/60000]\n",
      "loss: 8599.910156  [25600/60000]\n",
      "loss: 8827.591797  [51200/60000]\n",
      "Avg loss: 8844.177849 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 8341.518555  [    0/60000]\n",
      "loss: 8598.127930  [25600/60000]\n",
      "loss: 8722.509766  [51200/60000]\n",
      "Avg loss: 8841.982918 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 8322.829102  [    0/60000]\n",
      "loss: 8601.691406  [25600/60000]\n",
      "loss: 8755.809570  [51200/60000]\n",
      "Avg loss: 8852.152783 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 8413.282227  [    0/60000]\n",
      "loss: 8617.583984  [25600/60000]\n",
      "loss: 8706.461914  [51200/60000]\n",
      "Avg loss: 8831.922836 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 8297.356445  [    0/60000]\n",
      "loss: 8575.241211  [25600/60000]\n",
      "loss: 8801.323242  [51200/60000]\n",
      "Avg loss: 8824.120219 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 8404.434570  [    0/60000]\n",
      "loss: 8555.378906  [25600/60000]\n",
      "loss: 8795.483398  [51200/60000]\n",
      "Avg loss: 8817.843835 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 8374.235352  [    0/60000]\n",
      "loss: 8598.697266  [25600/60000]\n",
      "loss: 8714.800781  [51200/60000]\n",
      "Avg loss: 8837.078087 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 8332.580078  [    0/60000]\n",
      "loss: 8573.687500  [25600/60000]\n",
      "loss: 8770.863281  [51200/60000]\n",
      "Avg loss: 8866.929274 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 8456.371094  [    0/60000]\n",
      "loss: 8583.279297  [25600/60000]\n",
      "loss: 8758.500977  [51200/60000]\n",
      "Avg loss: 8831.595793 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 8302.862305  [    0/60000]\n",
      "loss: 8612.909180  [25600/60000]\n",
      "loss: 8674.154297  [51200/60000]\n",
      "Avg loss: 8802.023169 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 8366.238281  [    0/60000]\n",
      "loss: 8556.884766  [25600/60000]\n",
      "loss: 8835.030273  [51200/60000]\n",
      "Avg loss: 8838.334250 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 8341.583984  [    0/60000]\n",
      "loss: 8526.991211  [25600/60000]\n",
      "loss: 8717.340820  [51200/60000]\n",
      "Avg loss: 8794.209834 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 8321.153320  [    0/60000]\n",
      "loss: 8544.799805  [25600/60000]\n",
      "loss: 8660.363281  [51200/60000]\n",
      "Avg loss: 8842.455151 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 8405.481445  [    0/60000]\n",
      "loss: 8621.804688  [25600/60000]\n",
      "loss: 8695.362305  [51200/60000]\n",
      "Avg loss: 8806.550711 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 8398.406250  [    0/60000]\n",
      "loss: 8489.770508  [25600/60000]\n",
      "loss: 8760.138672  [51200/60000]\n",
      "Avg loss: 8804.361899 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 8285.423828  [    0/60000]\n",
      "loss: 8575.807617  [25600/60000]\n",
      "loss: 8758.902344  [51200/60000]\n",
      "Avg loss: 8820.803366 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 8345.846680  [    0/60000]\n",
      "loss: 8578.542969  [25600/60000]\n",
      "loss: 8700.084961  [51200/60000]\n",
      "Avg loss: 8791.087074 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 8361.726562  [    0/60000]\n",
      "loss: 8614.172852  [25600/60000]\n",
      "loss: 8738.481445  [51200/60000]\n",
      "Avg loss: 8804.830748 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 8337.697266  [    0/60000]\n",
      "loss: 8503.921875  [25600/60000]\n",
      "loss: 8726.892578  [51200/60000]\n",
      "Avg loss: 8822.123512 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 8358.278320  [    0/60000]\n",
      "loss: 8595.593750  [25600/60000]\n",
      "loss: 8709.113281  [51200/60000]\n",
      "Avg loss: 8816.631902 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 8299.367188  [    0/60000]\n",
      "loss: 8570.269531  [25600/60000]\n",
      "loss: 8729.648438  [51200/60000]\n",
      "Avg loss: 8823.909981 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 8346.776367  [    0/60000]\n",
      "loss: 8590.291992  [25600/60000]\n",
      "loss: 8711.784180  [51200/60000]\n",
      "Avg loss: 8806.802345 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 8318.799805  [    0/60000]\n",
      "loss: 8575.117188  [25600/60000]\n",
      "loss: 8741.441406  [51200/60000]\n",
      "Avg loss: 8787.568538 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 8324.777344  [    0/60000]\n",
      "loss: 8562.836914  [25600/60000]\n",
      "loss: 8684.490234  [51200/60000]\n",
      "Avg loss: 8818.051175 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 8414.751953  [    0/60000]\n",
      "loss: 8570.486328  [25600/60000]\n",
      "loss: 8737.786133  [51200/60000]\n",
      "Avg loss: 8820.537872 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 8387.862305  [    0/60000]\n",
      "loss: 8596.444336  [25600/60000]\n",
      "loss: 8756.581055  [51200/60000]\n",
      "Avg loss: 8798.516310 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 8367.354492  [    0/60000]\n",
      "loss: 8595.890625  [25600/60000]\n",
      "loss: 8766.717773  [51200/60000]\n",
      "Avg loss: 8770.489467 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 8316.094727  [    0/60000]\n",
      "loss: 8526.752930  [25600/60000]\n",
      "loss: 8756.488281  [51200/60000]\n",
      "Avg loss: 8782.455232 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 8278.624023  [    0/60000]\n",
      "loss: 8551.890625  [25600/60000]\n",
      "loss: 8636.103516  [51200/60000]\n",
      "Avg loss: 8776.693358 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 8359.450195  [    0/60000]\n",
      "loss: 8505.973633  [25600/60000]\n",
      "loss: 8718.117188  [51200/60000]\n",
      "Avg loss: 8780.324185 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 8349.445312  [    0/60000]\n",
      "loss: 8504.654297  [25600/60000]\n",
      "loss: 8738.568359  [51200/60000]\n",
      "Avg loss: 8775.008990 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 8338.485352  [    0/60000]\n",
      "loss: 8505.033203  [25600/60000]\n",
      "loss: 8694.039062  [51200/60000]\n",
      "Avg loss: 8805.748904 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 8374.241211  [    0/60000]\n",
      "loss: 8506.533203  [25600/60000]\n",
      "loss: 8702.739258  [51200/60000]\n",
      "Avg loss: 8764.060042 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 8315.638672  [    0/60000]\n",
      "loss: 8549.121094  [25600/60000]\n",
      "loss: 8695.425781  [51200/60000]\n",
      "Avg loss: 8774.599580 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 8268.491211  [    0/60000]\n",
      "loss: 8594.472656  [25600/60000]\n",
      "loss: 8734.748047  [51200/60000]\n",
      "Avg loss: 8797.892586 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 8303.974609  [    0/60000]\n",
      "loss: 8527.057617  [25600/60000]\n",
      "loss: 8674.890625  [51200/60000]\n",
      "Avg loss: 8763.594412 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 8351.798828  [    0/60000]\n",
      "loss: 8557.458984  [25600/60000]\n",
      "loss: 8666.026367  [51200/60000]\n",
      "Avg loss: 8765.952679 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 8289.734375  [    0/60000]\n",
      "loss: 8513.474609  [25600/60000]\n",
      "loss: 8666.581055  [51200/60000]\n",
      "Avg loss: 8770.389462 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 8280.910156  [    0/60000]\n",
      "loss: 8595.290039  [25600/60000]\n",
      "loss: 8686.451172  [51200/60000]\n",
      "Avg loss: 8765.800952 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 8307.972656  [    0/60000]\n",
      "loss: 8496.898438  [25600/60000]\n",
      "loss: 8654.593750  [51200/60000]\n",
      "Avg loss: 8785.549232 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 8427.771484  [    0/60000]\n",
      "loss: 8508.921875  [25600/60000]\n",
      "loss: 8804.880859  [51200/60000]\n",
      "Avg loss: 8753.623593 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 8280.961914  [    0/60000]\n",
      "loss: 8538.509766  [25600/60000]\n",
      "loss: 8673.551758  [51200/60000]\n",
      "Avg loss: 8781.380489 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 8349.390625  [    0/60000]\n",
      "loss: 8526.355469  [25600/60000]\n",
      "loss: 8628.092773  [51200/60000]\n",
      "Avg loss: 8768.026572 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 8329.833984  [    0/60000]\n",
      "loss: 8526.881836  [25600/60000]\n",
      "loss: 8638.682617  [51200/60000]\n",
      "Avg loss: 8752.400803 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 8266.351562  [    0/60000]\n",
      "loss: 8541.763672  [25600/60000]\n",
      "loss: 8721.119141  [51200/60000]\n",
      "Avg loss: 8747.266045 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 8257.763672  [    0/60000]\n",
      "loss: 8550.834961  [25600/60000]\n",
      "loss: 8646.898438  [51200/60000]\n",
      "Avg loss: 8747.825525 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 8326.784180  [    0/60000]\n",
      "loss: 8580.683594  [25600/60000]\n",
      "loss: 8640.277344  [51200/60000]\n",
      "Avg loss: 8786.505380 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 8325.036133  [    0/60000]\n",
      "loss: 8574.596680  [25600/60000]\n",
      "loss: 8676.078125  [51200/60000]\n",
      "Avg loss: 8781.004131 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 8315.449219  [    0/60000]\n",
      "loss: 8499.915039  [25600/60000]\n",
      "loss: 8619.985352  [51200/60000]\n",
      "Avg loss: 8775.519896 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 8308.099609  [    0/60000]\n",
      "loss: 8522.607422  [25600/60000]\n",
      "loss: 8626.322266  [51200/60000]\n",
      "Avg loss: 8757.768750 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 8283.654297  [    0/60000]\n",
      "loss: 8527.791992  [25600/60000]\n",
      "loss: 8642.633789  [51200/60000]\n",
      "Avg loss: 8739.651385 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 8310.877930  [    0/60000]\n",
      "loss: 8555.119141  [25600/60000]\n",
      "loss: 8691.750000  [51200/60000]\n",
      "Avg loss: 8753.052194 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 8297.898438  [    0/60000]\n",
      "loss: 8484.556641  [25600/60000]\n",
      "loss: 8619.438477  [51200/60000]\n",
      "Avg loss: 8757.959030 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 8263.885742  [    0/60000]\n",
      "loss: 8541.890625  [25600/60000]\n",
      "loss: 8591.213867  [51200/60000]\n",
      "Avg loss: 8790.399173 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 8309.047852  [    0/60000]\n",
      "loss: 8523.459961  [25600/60000]\n",
      "loss: 8659.352539  [51200/60000]\n",
      "Avg loss: 8751.896336 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 8284.238281  [    0/60000]\n",
      "loss: 8583.581055  [25600/60000]\n",
      "loss: 8612.199219  [51200/60000]\n",
      "Avg loss: 8734.379791 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 8233.664062  [    0/60000]\n",
      "loss: 8557.914062  [25600/60000]\n",
      "loss: 8669.228516  [51200/60000]\n",
      "Avg loss: 8726.340074 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 8193.031250  [    0/60000]\n",
      "loss: 8470.207031  [25600/60000]\n",
      "loss: 8625.409180  [51200/60000]\n",
      "Avg loss: 8736.644064 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 8255.395508  [    0/60000]\n",
      "loss: 8478.521484  [25600/60000]\n",
      "loss: 8610.814453  [51200/60000]\n",
      "Avg loss: 8773.099965 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 8349.373047  [    0/60000]\n",
      "loss: 8495.051758  [25600/60000]\n",
      "loss: 8616.406250  [51200/60000]\n",
      "Avg loss: 8761.646512 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 8255.688477  [    0/60000]\n",
      "loss: 8501.108398  [25600/60000]\n",
      "loss: 8668.077148  [51200/60000]\n",
      "Avg loss: 8772.847121 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 8313.358398  [    0/60000]\n",
      "loss: 8517.093750  [25600/60000]\n",
      "loss: 8700.375977  [51200/60000]\n",
      "Avg loss: 8742.268738 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 8245.449219  [    0/60000]\n",
      "loss: 8507.804688  [25600/60000]\n",
      "loss: 8596.011719  [51200/60000]\n",
      "Avg loss: 8747.570413 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 8263.199219  [    0/60000]\n",
      "loss: 8467.781250  [25600/60000]\n",
      "loss: 8580.985352  [51200/60000]\n",
      "Avg loss: 8724.282356 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 8198.806641  [    0/60000]\n",
      "loss: 8528.125000  [25600/60000]\n",
      "loss: 8632.362305  [51200/60000]\n",
      "Avg loss: 8757.527477 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 8230.415039  [    0/60000]\n",
      "loss: 8476.017578  [25600/60000]\n",
      "loss: 8620.735352  [51200/60000]\n",
      "Avg loss: 8738.454144 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 8303.820312  [    0/60000]\n",
      "loss: 8544.230469  [25600/60000]\n",
      "loss: 8601.822266  [51200/60000]\n",
      "Avg loss: 8752.332065 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 8316.951172  [    0/60000]\n",
      "loss: 8569.375000  [25600/60000]\n",
      "loss: 8645.494141  [51200/60000]\n",
      "Avg loss: 8742.765219 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 8272.773438  [    0/60000]\n",
      "loss: 8534.994141  [25600/60000]\n",
      "loss: 8612.321289  [51200/60000]\n",
      "Avg loss: 8740.337245 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 8313.869141  [    0/60000]\n",
      "loss: 8553.925781  [25600/60000]\n",
      "loss: 8567.975586  [51200/60000]\n",
      "Avg loss: 8766.497096 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 8260.942383  [    0/60000]\n",
      "loss: 8503.898438  [25600/60000]\n",
      "loss: 8649.350586  [51200/60000]\n",
      "Avg loss: 8734.780502 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 8252.193359  [    0/60000]\n",
      "loss: 8506.484375  [25600/60000]\n",
      "loss: 8674.205078  [51200/60000]\n",
      "Avg loss: 8781.018443 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 8442.310547  [    0/60000]\n",
      "loss: 8523.166016  [25600/60000]\n",
      "loss: 8640.376953  [51200/60000]\n",
      "Avg loss: 8755.671899 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 8234.601562  [    0/60000]\n",
      "loss: 8459.925781  [25600/60000]\n",
      "loss: 8636.611328  [51200/60000]\n",
      "Avg loss: 8781.518340 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 8353.903320  [    0/60000]\n",
      "loss: 8491.281250  [25600/60000]\n",
      "loss: 8623.013672  [51200/60000]\n",
      "Avg loss: 8762.425859 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 8337.485352  [    0/60000]\n",
      "loss: 8494.954102  [25600/60000]\n",
      "loss: 8566.586914  [51200/60000]\n",
      "Avg loss: 8718.863187 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 8281.966797  [    0/60000]\n",
      "loss: 8496.268555  [25600/60000]\n",
      "loss: 8549.373047  [51200/60000]\n",
      "Avg loss: 8739.426599 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 8215.023438  [    0/60000]\n",
      "loss: 8502.114258  [25600/60000]\n",
      "loss: 8601.828125  [51200/60000]\n",
      "Avg loss: 8742.735623 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 8324.019531  [    0/60000]\n",
      "loss: 8516.692383  [25600/60000]\n",
      "loss: 8542.739258  [51200/60000]\n",
      "Avg loss: 8777.610590 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 8211.126953  [    0/60000]\n",
      "loss: 8538.613281  [25600/60000]\n",
      "loss: 8627.247070  [51200/60000]\n",
      "Avg loss: 8720.516895 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 8261.011719  [    0/60000]\n",
      "loss: 8524.258789  [25600/60000]\n",
      "loss: 8661.648438  [51200/60000]\n",
      "Avg loss: 8741.895602 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 8307.361328  [    0/60000]\n",
      "loss: 8519.066406  [25600/60000]\n",
      "loss: 8677.476562  [51200/60000]\n",
      "Avg loss: 8716.756010 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 8220.947266  [    0/60000]\n",
      "loss: 8549.794922  [25600/60000]\n",
      "loss: 8582.218750  [51200/60000]\n",
      "Avg loss: 8744.178549 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 8268.792969  [    0/60000]\n",
      "loss: 8521.690430  [25600/60000]\n",
      "loss: 8612.599609  [51200/60000]\n",
      "Avg loss: 8724.770734 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 8235.841797  [    0/60000]\n",
      "loss: 8514.063477  [25600/60000]\n",
      "loss: 8544.732422  [51200/60000]\n",
      "Avg loss: 8730.616064 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 8185.106445  [    0/60000]\n",
      "loss: 8522.665039  [25600/60000]\n",
      "loss: 8576.791992  [51200/60000]\n",
      "Avg loss: 8723.459041 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 8258.781250  [    0/60000]\n",
      "loss: 8536.691406  [25600/60000]\n",
      "loss: 8647.555664  [51200/60000]\n",
      "Avg loss: 8742.212457 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 8313.107422  [    0/60000]\n",
      "loss: 8458.929688  [25600/60000]\n",
      "loss: 8589.327148  [51200/60000]\n",
      "Avg loss: 8730.329709 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 8249.957031  [    0/60000]\n",
      "loss: 8495.320312  [25600/60000]\n",
      "loss: 8562.334961  [51200/60000]\n",
      "Avg loss: 8715.645978 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 8250.870117  [    0/60000]\n",
      "loss: 8432.131836  [25600/60000]\n",
      "loss: 8519.616211  [51200/60000]\n",
      "Avg loss: 8725.810378 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 8209.385742  [    0/60000]\n",
      "loss: 8486.726562  [25600/60000]\n",
      "loss: 8519.597656  [51200/60000]\n",
      "Avg loss: 8759.855656 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 8300.678711  [    0/60000]\n",
      "loss: 8493.464844  [25600/60000]\n",
      "loss: 8614.880859  [51200/60000]\n",
      "Avg loss: 8713.308174 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 8236.552734  [    0/60000]\n",
      "loss: 8541.179688  [25600/60000]\n",
      "loss: 8611.303711  [51200/60000]\n",
      "Avg loss: 8731.505070 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 8230.277344  [    0/60000]\n",
      "loss: 8498.389648  [25600/60000]\n",
      "loss: 8612.105469  [51200/60000]\n",
      "Avg loss: 8734.229137 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 8211.753906  [    0/60000]\n",
      "loss: 8516.175781  [25600/60000]\n",
      "loss: 8529.876953  [51200/60000]\n",
      "Avg loss: 8709.628442 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 8209.140625  [    0/60000]\n",
      "loss: 8546.851562  [25600/60000]\n",
      "loss: 8549.764648  [51200/60000]\n",
      "Avg loss: 8725.831609 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 8277.070312  [    0/60000]\n",
      "loss: 8529.736328  [25600/60000]\n",
      "loss: 8517.749023  [51200/60000]\n",
      "Avg loss: 8739.596379 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 8271.694336  [    0/60000]\n",
      "loss: 8460.007812  [25600/60000]\n",
      "loss: 8559.184570  [51200/60000]\n",
      "Avg loss: 8735.272893 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 8295.686523  [    0/60000]\n",
      "loss: 8428.086914  [25600/60000]\n",
      "loss: 8590.191406  [51200/60000]\n",
      "Avg loss: 8721.548727 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 8181.320312  [    0/60000]\n",
      "loss: 8523.074219  [25600/60000]\n",
      "loss: 8614.346680  [51200/60000]\n",
      "Avg loss: 8740.916202 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 8294.693359  [    0/60000]\n",
      "loss: 8528.122070  [25600/60000]\n",
      "loss: 8615.249023  [51200/60000]\n",
      "Avg loss: 8746.071683 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 8245.399414  [    0/60000]\n",
      "loss: 8464.782227  [25600/60000]\n",
      "loss: 8575.421875  [51200/60000]\n",
      "Avg loss: 8744.514746 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 8248.822266  [    0/60000]\n",
      "loss: 8511.453125  [25600/60000]\n",
      "loss: 8558.040039  [51200/60000]\n",
      "Avg loss: 8722.447238 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 8142.882324  [    0/60000]\n",
      "loss: 8490.339844  [25600/60000]\n",
      "loss: 8592.573242  [51200/60000]\n",
      "Avg loss: 8722.368155 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 8279.643555  [    0/60000]\n",
      "loss: 8467.341797  [25600/60000]\n",
      "loss: 8574.999023  [51200/60000]\n",
      "Avg loss: 8732.646638 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 8244.709961  [    0/60000]\n",
      "loss: 8473.189453  [25600/60000]\n",
      "loss: 8567.478516  [51200/60000]\n",
      "Avg loss: 8727.990900 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 8280.329102  [    0/60000]\n",
      "loss: 8505.414062  [25600/60000]\n",
      "loss: 8627.347656  [51200/60000]\n",
      "Avg loss: 8745.778918 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 8241.170898  [    0/60000]\n",
      "loss: 8442.219727  [25600/60000]\n",
      "loss: 8591.325195  [51200/60000]\n",
      "Avg loss: 8742.839157 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 8252.927734  [    0/60000]\n",
      "loss: 8498.136719  [25600/60000]\n",
      "loss: 8589.507812  [51200/60000]\n",
      "Avg loss: 8710.295589 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 8199.506836  [    0/60000]\n",
      "loss: 8483.472656  [25600/60000]\n",
      "loss: 8601.848633  [51200/60000]\n",
      "Avg loss: 8722.016219 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 8215.627930  [    0/60000]\n",
      "loss: 8437.809570  [25600/60000]\n",
      "loss: 8578.630859  [51200/60000]\n",
      "Avg loss: 8708.014417 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 8199.663086  [    0/60000]\n",
      "loss: 8461.864258  [25600/60000]\n",
      "loss: 8513.378906  [51200/60000]\n",
      "Avg loss: 8707.144073 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 8191.692383  [    0/60000]\n",
      "loss: 8482.743164  [25600/60000]\n",
      "loss: 8554.165039  [51200/60000]\n",
      "Avg loss: 8699.084583 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 8204.051758  [    0/60000]\n",
      "loss: 8453.866211  [25600/60000]\n",
      "loss: 8550.296875  [51200/60000]\n",
      "Avg loss: 8756.362411 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 8237.396484  [    0/60000]\n",
      "loss: 8518.417969  [25600/60000]\n",
      "loss: 8557.902344  [51200/60000]\n",
      "Avg loss: 8734.064000 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 8261.801758  [    0/60000]\n",
      "loss: 8499.334961  [25600/60000]\n",
      "loss: 8573.150391  [51200/60000]\n",
      "Avg loss: 8702.005734 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 8129.604492  [    0/60000]\n",
      "loss: 8445.737305  [25600/60000]\n",
      "loss: 8545.862305  [51200/60000]\n",
      "Avg loss: 8743.441119 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 8244.904297  [    0/60000]\n",
      "loss: 8531.052734  [25600/60000]\n",
      "loss: 8557.582031  [51200/60000]\n",
      "Avg loss: 8729.300385 \n",
      "\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 200\n",
    "loss_series = []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    avg_loss = train(train_dataloader, model, loss_fn, optimizer)\n",
    "    loss_series.append(avg_loss)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n",
    "plt.plot(range(1,epochs +1), loss_series)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Average loss')\n",
    "plt.savefig(R\"convolutional_VAE_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "109825ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"convolutional_VAE.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5581fe10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (encoder1): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Flatten(start_dim=1, end_dim=-1)\n",
       "    (8): Linear(in_features=288, out_features=128, bias=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "  )\n",
       "  (encoderMu): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (encoderlogvar): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=128, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=128, out_features=288, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Unflatten(dim=1, unflattened_size=(32, 3, 3))\n",
       "    (5): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (9): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): ConvTranspose2d(8, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (12): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork(latent_dim).to(device)\n",
    "model.load_state_dict(torch.load(R\"convolutional_VAE.pth\"))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27f4e1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_data, batch_size=60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f59c5da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(model, batch_size):\n",
    "    mu = torch.zeros([batch_size, latent_dim], device=device)\n",
    "    logvar = torch.zeros([batch_size, latent_dim], device=device)\n",
    "    z = model.reparameterize(mu, logvar)\n",
    "    img = model.decoder(z)\n",
    "    return img\n",
    "\n",
    "def generate_many_samples(model, count, batch_size):\n",
    "    n_batches = int(count / batch_size) \n",
    "    result = torch.zeros(size=(0,1,28,28))\n",
    "    for i in range(n_batches):\n",
    "        samples = generate_samples(model, batch_size).detach().cpu()\n",
    "        result = torch.cat([result, samples], dim = 0)\n",
    "    return result\n",
    "\n",
    "many_samples = generate_many_samples(model, 10000, batch_size=100)\n",
    "np.save(R\"convolutional_VAE_samples.npy\", many_samples.squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e221762e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(12, 2))\n",
    "cols, rows = 5, 1\n",
    "for i in range(1,  cols + 1):\n",
    "    img = many_samples[i]\n",
    "    img=img.to('cpu').detach().numpy()\n",
    "    img = img.reshape((1,1,28,28))\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray_r\")\n",
    "plt.savefig(\"convolutional_samples.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "adf7b13d16fc3238351416f6263c211a3edac063bd5b935410de812cd202e11b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
